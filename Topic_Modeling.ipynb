{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas\n",
    "#wordFreq = pandas.read_csv('WordFrequencyMatrix.csv')\n",
    "#wordFreq.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pandas.read_excel('articlesAnalyzed.xlsx')\n",
    "articles.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE on Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = [i.split() for i in articles.MWE] # list of articles\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sentences=art,size=32, sg=1, window = 9, min_count=2,seed = 20, workers=2)\n",
    "\n",
    "#You can save the model so you can reuse it later\n",
    "w2v_model.save('word2VecModel32.w2v')\n",
    "\n",
    "#You can reload a saved model\n",
    "#w2v_model = gensim.models.Word2Vec.load('word2VecModel.w2v')\n",
    "print (len(w2v_model.wv.vocab)) #words and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the vocabulary from the 32-dimensional space\n",
    "X_32D=w2v_model[w2v_model.wv.vocab]\n",
    "# Transform the data and load up a Panda dataframe\n",
    "tSNE = TSNE(n_components=2, metric='cosine', perplexity=20, learning_rate=200, random_state=0, n_iter = 1000)\n",
    "X_2D = tSNE.fit_transform(X_32D)\n",
    "wordTSNE = pandas.DataFrame(X_2D, columns=['xWord','yWord'])\n",
    "wordTSNE['Word'] = w2v_model.wv.vocab.keys()\n",
    "wordTSNE = wordTSNE[['Word','xWord','yWord']]\n",
    "wordTSNE.to_excel('word2Vec.xlsx',index = False)\n",
    "wordTSNE.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('words in word2vec',len(wordTSNE.Word))\n",
    "\n",
    "words = []\n",
    "for i in articles.MWE:\n",
    "    for j in i.split():\n",
    "        words.append(j)\n",
    "print('words in dataset',len(set(words)))\n",
    "# why not the same? min_count of 2 decreasing word2Vec count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.most_similar('mexico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec? \n",
    "# Word2Vec mapped to each document then TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RCeballos\\Anaconda\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\RCeballos\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import nltk\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format(\"C:\\\\Users\\\\RCeballos\\\\OneDrive - St. John's University\\\\Spring 2019\\\\NLP\\\\Project\\\\Project 2\\\\GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "# wv = KeyedVectors.load_word2vec_format(\"C:\\\\Users\\\\Reyes\\\\OneDrive - St. John's University\\\\Spring 2019\\\\NLP\\\\Project\\\\Project 2\\\\GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)\n",
    "# https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "#  load a word2vec model. pre-trained by Google on a 100 billion word Google News corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW average the two word vectors\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        #logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RCeballos\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# apply word vector averaging to tokenized text.\n",
    "\n",
    "MWEtokenized = []\n",
    "for i in articles.MWE:\n",
    "    MWEtokenized.append(w2v_tokenize_text(i))\n",
    "\n",
    "MWEtokenized_word_average = word_averaging_list(wv,MWEtokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MWEtokenized_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving the vocabulary from the 32-dimensional space\n",
    "#X_32D=w2v_model[w2v_model.wv.vocab]\n",
    "# Transform the data and load up a Panda dataframe\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tSNE = TSNE(n_components=2, metric='cosine', perplexity=20, learning_rate=200, random_state=0, n_iter = 1000)\n",
    "X_2D = tSNE.fit_transform(MWEtokenized_word_average)\n",
    "wordTSNE = pandas.DataFrame(X_2D, columns=['Xdoc2vec','Ydoc2vec'])\n",
    "articles = articles.join(wordTSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "listMWE = [i.split() for i in articles.MWE]\n",
    "\n",
    "dictionary = corpora.Dictionary(listMWE)\n",
    "corpus = [dictionary.doc2bow(article.split()) for article in articles.MWE]\n",
    "dictionary.token2id\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.ctime())\n",
    "\n",
    "articlesAllTopics = {} # all possible labels\n",
    "topicK = [i for i in range(2,12)] # number of topics\n",
    "topicDic = {} #holds all topics and the words\n",
    "models = {} #all models to later pick the best one\n",
    "ModelEvaluation = [] # Perplexity /Coherence Score\n",
    "#Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. \n",
    "#topic coherence score has been more helpful.\n",
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "for k in topicK:\n",
    "    iterations = 100 # 20-30 good for testing, 50-100 better for final\n",
    "    topic_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=k, random_state=1, id2word = dictionary, passes = iterations)\n",
    "\n",
    "    topics = topic_model.print_topics(num_words = 30)\n",
    "    models['k'+str(k)] = topics # add model to dict\n",
    "\n",
    "    for i in topics:\n",
    "        topicWords = [] #all words\n",
    "        for j in i[1].split(' + '):\n",
    "            topicWords.append(j.split('*')[1][1:-1]) #words\n",
    "        topicDic['k'+str(k)+'t'+str(i[0])] = topicWords\n",
    "    print(k)\n",
    "\n",
    "    topic = [] # main topic\n",
    "    percent = [] # main topic %\n",
    "    subtopic = [] # 2nd topic\n",
    "    subPercent = [] # 2nd topic %\n",
    "\n",
    "    for i in range(0,len(articles.id)):\n",
    "        t = topic_model.get_document_topics(corpus[i])\n",
    "        t.sort(reverse = True, key=lambda x: x[1])\n",
    "        topic.append(t[0][0])\n",
    "        percent.append(t[0][1])\n",
    "        if len(t) > 1:\n",
    "            subtopic.append(t[1][0])\n",
    "            subPercent.append(t[1][1])\n",
    "        else:\n",
    "            subtopic.append('NA')\n",
    "            subPercent.append(0)\n",
    "\n",
    "    articlesAllTopics['Topic'+str(k)] = topic\n",
    "    articlesAllTopics['Percent'+str(k)] = percent\n",
    "    articlesAllTopics['Subtopic'+str(k)] = subtopic\n",
    "    articlesAllTopics['SubPercent'+str(k)] = subPercent\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=topic_model, texts=listMWE, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    ModelEvaluation.append([str(k),topic_model.log_perplexity(corpus), coherence_lda]) # a measure of how good the model is. lower the better.\n",
    "    \n",
    "    # perplexity - a measure of how good the model is. lower the better.\n",
    "    # coherence score of each topic then aggregated. the higher the better\n",
    "    # https://rare-technologies.com/what-is-topic-coherence/\n",
    "    \n",
    "                            \n",
    "    # Visualize the topics. Saves to html file\n",
    "    vis = pyLDAvis.gensim.prepare(topic_model, corpus, dictionary)\n",
    "    pyLDAvis.save_html(vis, 'ldaGraph'+str(k)+'.html')\n",
    "    #https://pyldavis.readthedocs.io/en/latest/modules/API.html#pyLDAvis.save_html\n",
    "    \n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicDic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ME = {'Topic#':[],'Perplexity':[],'Coherence':[]}\n",
    "for i in ModelEvaluation:\n",
    "    ME['Topic#'].append(i[0])\n",
    "    ME['Perplexity'].append(i[1])\n",
    "    ME['Coherence'].append(i[2])\n",
    "MEdf = pandas.DataFrame(ME)\n",
    "MEdf.to_excel('ModelEvaluation.xlsx',index = False)\n",
    "MEdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicWords = pandas.DataFrame(topicDic )\n",
    "articlesAllTopics = pandas.DataFrame(articlesAllTopics)\n",
    "topicWords.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlesAllTopics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicWords.to_excel('topicWords1.xlsx',index = False)\n",
    "#review all words associated with each topic\n",
    "articlesAllTopics.to_csv('articlesAllTopics.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose K\n",
    "Use to visualize then choose a K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "chooseTopic = pandas.read_csv('articlesAllTopics.csv')\n",
    "chooseTopic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'w'\n",
    "head = True\n",
    "\n",
    "for i in range(0,len(chooseTopic.columns),4):\n",
    "    t = pandas.DataFrame({'Topic' : [chooseTopic.columns[i]]*len(chooseTopic)})\n",
    "    t = t.join(chooseTopic.iloc[:,i:i+4])\n",
    "    t.to_csv('chooseTopicUnpivoted.csv',mode = m, index= False, header = head)\n",
    "    m = 'a'\n",
    "    head = False\n",
    "    print(i,'done')\n",
    "# some NA's in subtopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "url = 'https://www.youtube.com/watch?v=VYOjWnS4cMY' #this is america\n",
    "webbrowser.open(url, new=1, autoraise=True)\n",
    "# notification that topic modeling is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pause *** Do not proceed until you are satified with the number of K\n",
    "Review all saved excel files and html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge K to Articles\n",
    "After having chosen the right K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Percent2</th>\n",
       "      <th>Subtopic2</th>\n",
       "      <th>SubPercent2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Percent3</th>\n",
       "      <th>Subtopic3</th>\n",
       "      <th>SubPercent3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Percent4</th>\n",
       "      <th>...</th>\n",
       "      <th>Subtopic9</th>\n",
       "      <th>SubPercent9</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Percent10</th>\n",
       "      <th>Subtopic10</th>\n",
       "      <th>SubPercent10</th>\n",
       "      <th>Topic11</th>\n",
       "      <th>Percent11</th>\n",
       "      <th>Subtopic11</th>\n",
       "      <th>SubPercent11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>0</td>\n",
       "      <td>0.936597</td>\n",
       "      <td>1</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>2</td>\n",
       "      <td>0.491452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.468730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750995</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>5</td>\n",
       "      <td>0.410002</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.210001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.409090</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.209091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>0</td>\n",
       "      <td>0.968683</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031317</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646079</td>\n",
       "      <td>2</td>\n",
       "      <td>0.335618</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961064</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>7</td>\n",
       "      <td>0.637699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133863</td>\n",
       "      <td>7</td>\n",
       "      <td>0.464668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.156656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>0</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>2</td>\n",
       "      <td>0.711054</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260141</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366597</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686824</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.170536</td>\n",
       "      <td>0</td>\n",
       "      <td>0.481978</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.278934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic2  Percent2  Subtopic2  SubPercent2  Topic3  Percent3  Subtopic3  \\\n",
       "21458       0  0.936597          1     0.063403       2  0.491452          0   \n",
       "21459       0  0.968683          1     0.031317       0  0.646079          2   \n",
       "21460       0  0.952328          1     0.047672       2  0.711054          0   \n",
       "\n",
       "       SubPercent3  Topic4  Percent4  ...  Subtopic9  SubPercent9  Topic10  \\\n",
       "21458     0.468730       0  0.750995  ...        4.0     0.311107        5   \n",
       "21459     0.335618       2  0.961064  ...        1.0     0.160200        7   \n",
       "21460     0.260141       1  0.366597  ...        4.0     0.250169        0   \n",
       "\n",
       "       Percent10  Subtopic10  SubPercent10  Topic11  Percent11  Subtopic11  \\\n",
       "21458   0.410002         6.0      0.210001        5   0.409090         4.0   \n",
       "21459   0.637699         1.0      0.133863        7   0.464668         1.0   \n",
       "21460   0.686824         4.0      0.170536        0   0.481978         4.0   \n",
       "\n",
       "       SubPercent11  \n",
       "21458      0.209091  \n",
       "21459      0.156656  \n",
       "21460      0.278934  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "chooseTopic = pandas.read_csv('articlesAllTopics.csv')\n",
    "chooseTopic.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Percent5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>0</td>\n",
       "      <td>0.713760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>2</td>\n",
       "      <td>0.687314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>0</td>\n",
       "      <td>0.323158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic5  Percent5\n",
       "21458       0  0.713760\n",
       "21459       2  0.687314\n",
       "21460       0  0.323158"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TopicKchosen = ['Topic5', 'Percent5']\n",
    "chooseTopic = chooseTopic.filter(items = TopicKchosen) # choose k columns\n",
    "chooseTopic.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>locations</th>\n",
       "      <th>subjects</th>\n",
       "      <th>...</th>\n",
       "      <th>lemma</th>\n",
       "      <th>polaritySentiWord</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>Vpolarity</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>MWE</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21458</th>\n",
       "      <td>5c8acca540d36ff0707a71ed</td>\n",
       "      <td>National</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/12/31/us/joyful-h...</td>\n",
       "      <td>1093</td>\n",
       "      <td>['Hollywood (Calif)', 'Harris County (Tex)']</td>\n",
       "      <td>['Race and Ethnicity', 'Hispanic-Americans', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>joyful headline race equality story race many ...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>positive</td>\n",
       "      <td>joyful headline race equality story race  publ...</td>\n",
       "      <td>54.823307</td>\n",
       "      <td>39.942757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>5c8abf1140d36ff0707722ba</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/12/30/us/politics...</td>\n",
       "      <td>1461</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Shutdowns (Institutional)', 'Border Barriers...</td>\n",
       "      <td>...</td>\n",
       "      <td>trump dig darkening hope deal end shutdown pre...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.033</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dig  hope deal end shutdown president repeate...</td>\n",
       "      <td>27.929886</td>\n",
       "      <td>-38.241348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>5c8ae37240d36ff070800a33</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Interactive Feature</td>\n",
       "      <td>https://www.nytimes.com/interactive/2018/us/20...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Two Thousand Eighteen']</td>\n",
       "      <td>...</td>\n",
       "      <td>2018 year visual story graphic selected time g...</td>\n",
       "      <td>0.625</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2018 year visual story graphic selected time g...</td>\n",
       "      <td>42.510998</td>\n",
       "      <td>-52.691666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id   news_desk   pub_date section  \\\n",
       "21458  5c8acca540d36ff0707a71ed    National 2018-12-31    U.S.   \n",
       "21459  5c8abf1140d36ff0707722ba  Washington 2018-12-31    U.S.   \n",
       "21460  5c8ae37240d36ff070800a33        U.S. 2018-12-31    U.S.   \n",
       "\n",
       "                   source                 type  \\\n",
       "21458  The New York Times                 News   \n",
       "21459  The New York Times                 News   \n",
       "21460  The New York Times  Interactive Feature   \n",
       "\n",
       "                                                     url  word_count  \\\n",
       "21458  https://www.nytimes.com/2018/12/31/us/joyful-h...        1093   \n",
       "21459  https://www.nytimes.com/2018/12/30/us/politics...        1461   \n",
       "21460  https://www.nytimes.com/interactive/2018/us/20...           0   \n",
       "\n",
       "                                          locations  \\\n",
       "21458  ['Hollywood (Calif)', 'Harris County (Tex)']   \n",
       "21459                                            []   \n",
       "21460                                            []   \n",
       "\n",
       "                                                subjects  ...  \\\n",
       "21458  ['Race and Ethnicity', 'Hispanic-Americans', '...  ...   \n",
       "21459  ['Shutdowns (Institutional)', 'Border Barriers...  ...   \n",
       "21460                          ['Two Thousand Eighteen']  ...   \n",
       "\n",
       "                                                   lemma polaritySentiWord  \\\n",
       "21458  joyful headline race equality story race many ...             0.125   \n",
       "21459  trump dig darkening hope deal end shutdown pre...             0.750   \n",
       "21460  2018 year visual story graphic selected time g...             0.625   \n",
       "\n",
       "      sentimentSentiWord Vpolarity   Vpos   Vneg Vsentiment  \\\n",
       "21458            neutral    0.8591  0.373  0.000   positive   \n",
       "21459           positive    0.3195  0.085  0.033    neutral   \n",
       "21460           positive    0.0000  0.000  0.000    neutral   \n",
       "\n",
       "                                                     MWE     Xt_SNE     Yt_SNE  \n",
       "21458  joyful headline race equality story race  publ...  54.823307  39.942757  \n",
       "21459   dig  hope deal end shutdown president repeate...  27.929886 -38.241348  \n",
       "21460  2018 year visual story graphic selected time g...  42.510998 -52.691666  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pandas.read_excel('articlesAnalyzed.xlsx')\n",
    "articles.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>locations</th>\n",
       "      <th>subjects</th>\n",
       "      <th>...</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>Vpolarity</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>MWE</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Percent5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56869e9438f0d85a6c1302fc</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Video</td>\n",
       "      <td>https://www.nytimes.com/video/us/1000000041215...</td>\n",
       "      <td>26</td>\n",
       "      <td>['Chicago (Ill)']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.8225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>negative</td>\n",
       "      <td>protester denounce chicago mayor demonstrator ...</td>\n",
       "      <td>9.847380</td>\n",
       "      <td>-42.725788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5686ced038f0d82225326f1e</td>\n",
       "      <td>Politics</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Blog</td>\n",
       "      <td>https://www.nytimes.com/politics/first-draft/2...</td>\n",
       "      <td>374</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Campaign Finance', 'Presidential Election of...</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>negative</td>\n",
       "      <td>hillary_clinton raised million last month hill...</td>\n",
       "      <td>-3.512983</td>\n",
       "      <td>-39.470772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id news_desk   pub_date section              source  \\\n",
       "0  56869e9438f0d85a6c1302fc      U.S. 2016-01-01    U.S.             Reuters   \n",
       "1  5686ced038f0d82225326f1e  Politics 2016-01-01    U.S.  The New York Times   \n",
       "\n",
       "    type                                                url  word_count  \\\n",
       "0  Video  https://www.nytimes.com/video/us/1000000041215...          26   \n",
       "1   Blog  https://www.nytimes.com/politics/first-draft/2...         374   \n",
       "\n",
       "           locations                                           subjects  ...  \\\n",
       "0  ['Chicago (Ill)']                                                 []  ...   \n",
       "1                 []  ['Campaign Finance', 'Presidential Election of...  ...   \n",
       "\n",
       "  sentimentSentiWord Vpolarity Vpos   Vneg Vsentiment  \\\n",
       "0            neutral   -0.8225  0.0  0.298   negative   \n",
       "1            neutral   -0.5994  0.0  0.091   negative   \n",
       "\n",
       "                                                 MWE    Xt_SNE     Yt_SNE  \\\n",
       "0  protester denounce chicago mayor demonstrator ...  9.847380 -42.725788   \n",
       "1  hillary_clinton raised million last month hill... -3.512983 -39.470772   \n",
       "\n",
       "  Topic5  Percent5  \n",
       "0      1  0.812189  \n",
       "1      0  0.352895  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = articles.join(chooseTopic)\n",
    "articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Topic Names to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleID</th>\n",
       "      <th>Word</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>headlineSnippet</th>\n",
       "      <th>polaritySentiWord</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>Vpolarity</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Percent</th>\n",
       "      <th>xWord</th>\n",
       "      <th>yWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568c1b3538f0d803f4a0c4b8</td>\n",
       "      <td>000</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2016/01/06/us/in-west-...</td>\n",
       "      <td>811</td>\n",
       "      <td>Blizzard Buried Some Dairy Cows in the Snow; 3...</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.148</td>\n",
       "      <td>negative</td>\n",
       "      <td>20.894001</td>\n",
       "      <td>-5.72399</td>\n",
       "      <td>2</td>\n",
       "      <td>0.451726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ArticleID Word   pub_date              source  type  \\\n",
       "0  568c1b3538f0d803f4a0c4b8  000 2016-01-06  The New York Times  News   \n",
       "\n",
       "                                                 url  word_count  \\\n",
       "0  https://www.nytimes.com/2016/01/06/us/in-west-...         811   \n",
       "\n",
       "                                     headlineSnippet  polaritySentiWord  \\\n",
       "0  Blizzard Buried Some Dairy Cows in the Snow; 3...              -1.25   \n",
       "\n",
       "  sentimentSentiWord  Vpolarity   Vpos   Vneg Vsentiment     Xt_SNE   Yt_SNE  \\\n",
       "0           negative    -0.8126  0.022  0.148   negative  20.894001 -5.72399   \n",
       "\n",
       "   Topic   Percent  xWord  yWord  \n",
       "0      2  0.451726    NaN    NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = articles.rename(index = str, columns= {TopicKchosen[0]:'Topic',TopicKchosen[1]:'Percent'})\n",
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Death/Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Political Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Scandals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Topic Description\n",
       "0      0          Election\n",
       "1      1    Death/Disaster\n",
       "2      2      Trump Issues\n",
       "3      3  Political Issues\n",
       "4      4          Scandals"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicNames = pandas.read_excel('Topic Names.xlsx')\n",
    "topicNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleID</th>\n",
       "      <th>Word</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>headlineSnippet</th>\n",
       "      <th>polaritySentiWord</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>...</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Percent</th>\n",
       "      <th>xWord</th>\n",
       "      <th>yWord</th>\n",
       "      <th>Topic Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568c1b3538f0d803f4a0c4b8</td>\n",
       "      <td>000</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2016/01/06/us/in-west-...</td>\n",
       "      <td>811</td>\n",
       "      <td>Blizzard Buried Some Dairy Cows in the Snow; 3...</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.148</td>\n",
       "      <td>negative</td>\n",
       "      <td>20.894001</td>\n",
       "      <td>-5.72399</td>\n",
       "      <td>2</td>\n",
       "      <td>0.451726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump Issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ArticleID Word   pub_date              source  type  \\\n",
       "0  568c1b3538f0d803f4a0c4b8  000 2016-01-06  The New York Times  News   \n",
       "\n",
       "                                                 url  word_count  \\\n",
       "0  https://www.nytimes.com/2016/01/06/us/in-west-...         811   \n",
       "\n",
       "                                     headlineSnippet  polaritySentiWord  \\\n",
       "0  Blizzard Buried Some Dairy Cows in the Snow; 3...              -1.25   \n",
       "\n",
       "  sentimentSentiWord  ...   Vpos   Vneg  Vsentiment     Xt_SNE   Yt_SNE  \\\n",
       "0           negative  ...  0.022  0.148    negative  20.894001 -5.72399   \n",
       "\n",
       "   Topic   Percent  xWord  yWord  Topic Description  \n",
       "0      2  0.451726    NaN    NaN       Trump Issues  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pandas.merge(articles, topicNames, how='left', on='Topic')\n",
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Articles DataFrame and wordFrequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>380599</th>\n",
       "      <td>5c8a081640d36ff0703f5b04</td>\n",
       "      <td>zinkes</td>\n",
       "      <td>0.360993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380600</th>\n",
       "      <td>5c88b59040d36ff070c72f72</td>\n",
       "      <td>zone</td>\n",
       "      <td>0.272855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380601</th>\n",
       "      <td>5c8ae47b40d36ff070803e02</td>\n",
       "      <td>zone</td>\n",
       "      <td>0.277838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ArticleID    Word     Count\n",
       "380599  5c8a081640d36ff0703f5b04  zinkes  0.360993\n",
       "380600  5c88b59040d36ff070c72f72    zone  0.272855\n",
       "380601  5c8ae47b40d36ff070803e02    zone  0.277838"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFreq1 = pandas.read_csv('wordFreq1.csv')\n",
    "wordFreq1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>locations</th>\n",
       "      <th>subjects</th>\n",
       "      <th>...</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>Vpolarity</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>MWE</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Percent5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56869e9438f0d85a6c1302fc</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Video</td>\n",
       "      <td>https://www.nytimes.com/video/us/1000000041215...</td>\n",
       "      <td>26</td>\n",
       "      <td>['Chicago (Ill)']</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>-0.8225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>negative</td>\n",
       "      <td>protester denounce chicago mayor demonstrator ...</td>\n",
       "      <td>9.84738</td>\n",
       "      <td>-42.725788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id news_desk   pub_date section   source   type  \\\n",
       "0  56869e9438f0d85a6c1302fc      U.S. 2016-01-01    U.S.  Reuters  Video   \n",
       "\n",
       "                                                 url  word_count  \\\n",
       "0  https://www.nytimes.com/video/us/1000000041215...          26   \n",
       "\n",
       "           locations subjects  ... sentimentSentiWord Vpolarity Vpos   Vneg  \\\n",
       "0  ['Chicago (Ill)']       []  ...            neutral   -0.8225  0.0  0.298   \n",
       "\n",
       "  Vsentiment                                                MWE   Xt_SNE  \\\n",
       "0   negative  protester denounce chicago mayor demonstrator ...  9.84738   \n",
       "\n",
       "      Yt_SNE Topic5  Percent5  \n",
       "0 -42.725788      1  0.812189  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.rename(columns = {articles.columns[0]:'ArticleID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "      <th>news_desk</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>Vpolarity</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>MWE</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Percent5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568c1b3538f0d803f4a0c4b8</td>\n",
       "      <td>000</td>\n",
       "      <td>0.218475</td>\n",
       "      <td>National</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2016/01/06/us/in-west-...</td>\n",
       "      <td>811</td>\n",
       "      <td>...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.148</td>\n",
       "      <td>negative</td>\n",
       "      <td>blizzard buried dairy cow snow 35,000 die 35,0...</td>\n",
       "      <td>20.894001</td>\n",
       "      <td>-5.72399</td>\n",
       "      <td>2</td>\n",
       "      <td>0.451726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ArticleID Word     Count news_desk   pub_date section  \\\n",
       "0  568c1b3538f0d803f4a0c4b8  000  0.218475  National 2016-01-06    U.S.   \n",
       "\n",
       "               source  type  \\\n",
       "0  The New York Times  News   \n",
       "\n",
       "                                                 url  word_count  ...  \\\n",
       "0  https://www.nytimes.com/2016/01/06/us/in-west-...         811  ...   \n",
       "\n",
       "  sentimentSentiWord Vpolarity   Vpos   Vneg Vsentiment  \\\n",
       "0           negative   -0.8126  0.022  0.148   negative   \n",
       "\n",
       "                                                 MWE     Xt_SNE   Yt_SNE  \\\n",
       "0  blizzard buried dairy cow snow 35,000 die 35,0...  20.894001 -5.72399   \n",
       "\n",
       "  Topic5  Percent5  \n",
       "0      2  0.451726  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pandas.merge(wordFreq1, articles, how='outer', on='ArticleID')\n",
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ArticleID', 'Word', 'Count', 'news_desk', 'pub_date', 'section',\n",
       "       'source', 'type', 'url', 'word_count', 'locations', 'subjects',\n",
       "       'headline', 'snippet', 'headlineSnippet', 'tokens', 'tokensNoPunc',\n",
       "       'tokensFiltered', 'postag', 'stem', 'lemma', 'polaritySentiWord',\n",
       "       'sentimentSentiWord', 'Vpolarity', 'Vpos', 'Vneg', 'Vsentiment', 'MWE',\n",
       "       'Xt_SNE', 'Yt_SNE', 'Topic5', 'Percent5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined.filter(items = ['ArticleID', 'Word', 'pub_date', 'source', 'type', 'url', 'word_count', 'headlineSnippet', \n",
    "                                    'Vpolarity', 'Vpos', 'Vneg', 'Vsentiment', 'Xt_SNE', 'Yt_SNE', TopicKchosen[0], TopicKchosen[1], \n",
    "                                    'Topic Description', 'Xdoc2vec','Ydoc2vec' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380603, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>xWord</th>\n",
       "      <th>yWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>protester</td>\n",
       "      <td>26.249994</td>\n",
       "      <td>67.999649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>denounce</td>\n",
       "      <td>9.332670</td>\n",
       "      <td>-55.858910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicago</td>\n",
       "      <td>49.228859</td>\n",
       "      <td>66.641846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mayor</td>\n",
       "      <td>-4.235312</td>\n",
       "      <td>74.246544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>demonstrator</td>\n",
       "      <td>26.032663</td>\n",
       "      <td>67.737495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word      xWord      yWord\n",
       "0     protester  26.249994  67.999649\n",
       "1      denounce   9.332670 -55.858910\n",
       "2       chicago  49.228859  66.641846\n",
       "3         mayor  -4.235312  74.246544\n",
       "4  demonstrator  26.032663  67.737495"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Vec = pandas.read_excel('word2Vec.xlsx')\n",
    "word2Vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleID</th>\n",
       "      <th>Word</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>word_count</th>\n",
       "      <th>headlineSnippet</th>\n",
       "      <th>polaritySentiWord</th>\n",
       "      <th>sentimentSentiWord</th>\n",
       "      <th>Vpolarity</th>\n",
       "      <th>Vpos</th>\n",
       "      <th>Vneg</th>\n",
       "      <th>Vsentiment</th>\n",
       "      <th>Xt_SNE</th>\n",
       "      <th>Yt_SNE</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Percent5</th>\n",
       "      <th>xWord</th>\n",
       "      <th>yWord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568c1b3538f0d803f4a0c4b8</td>\n",
       "      <td>000</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2016/01/06/us/in-west-...</td>\n",
       "      <td>811</td>\n",
       "      <td>Blizzard Buried Some Dairy Cows in the Snow; 3...</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.8126</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.148</td>\n",
       "      <td>negative</td>\n",
       "      <td>20.894001</td>\n",
       "      <td>-5.72399</td>\n",
       "      <td>2</td>\n",
       "      <td>0.451726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ArticleID Word   pub_date              source  type  \\\n",
       "0  568c1b3538f0d803f4a0c4b8  000 2016-01-06  The New York Times  News   \n",
       "\n",
       "                                                 url  word_count  \\\n",
       "0  https://www.nytimes.com/2016/01/06/us/in-west-...         811   \n",
       "\n",
       "                                     headlineSnippet  polaritySentiWord  \\\n",
       "0  Blizzard Buried Some Dairy Cows in the Snow; 3...              -1.25   \n",
       "\n",
       "  sentimentSentiWord  Vpolarity   Vpos   Vneg Vsentiment     Xt_SNE   Yt_SNE  \\\n",
       "0           negative    -0.8126  0.022  0.148   negative  20.894001 -5.72399   \n",
       "\n",
       "   Topic5  Percent5  xWord  yWord  \n",
       "0       2  0.451726    NaN    NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pandas.merge(combined, word2Vec, how='left', on='Word')\n",
    "combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380603, 20)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to File Separate from Term Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.to_excel('articlesTopic.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('NYTArticles.csv',index = False) # joined files for Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
