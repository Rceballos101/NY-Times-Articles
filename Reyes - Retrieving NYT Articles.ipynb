{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.nytimes.com/apis\n",
    "# https://developer.nytimes.com/docs/articlesearch-product/1/overview\n",
    "# www.lucenetutorial.com/lucene-query-syntax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='api-key=zBxlhvG69zXIH0BooIEibFf56eJpv5Ny'\n",
    "api_site = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for politics\n",
    "desk = \"fq=news_desk:\"\n",
    "# pub_date: Timestamp (YYYY-MM-DD)\n",
    "dates = \"begin_date=20180101&end_date=20180331\"\n",
    "section = \"fq=section_name:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section Name Values\n",
    "sectionNV = ['Today%27s%20Headlines','U.S.','Washington','Week in Review'] #list of Sections\n",
    "\n",
    "# News Desk Values\n",
    "newsDesk = ['Editorial','National','OpEd','Politics','U.S.','Washington'] #list of NewsDesks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib.request\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two rate limits per API: 4,000 requests per day and 10 requests per minute. You should sleep 6 seconds between calls to avoid hitting the per minute rate limit.\n",
    "\n",
    "The Article Search API returns a max of 10 results at a time. \n",
    "The meta node in the response contains the total number of matches (\"hits\") and the current offset. \n",
    "Use the page query parameter to paginate thru results (page=0 for results 1-10, page=1 for 11-20, ...). \n",
    "You can paginate thru up to 100 pages (1,000 results). If you get too many results try filtering by date range.\n",
    "\n",
    "page: must be less than or equal to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateLimit = 0\n",
    "# rate limit is per day!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Sun Mar 31 11:45:31 2019\n",
      "Current NewsDesk Editorial has  180 articles\n",
      "1.8 minutes until next newsDesk or max 20 mins Sun Mar 31 11:45:33 2019\n",
      "Current rate is:  635\n",
      "Current NewsDesk National has  538 articles\n",
      "5.3 minutes until next newsDesk or max 20 mins Sun Mar 31 11:47:39 2019\n",
      "Current rate is:  654\n",
      "Current NewsDesk OpEd has  1197 articles\n",
      "11.9 minutes until next newsDesk or max 20 mins Sun Mar 31 11:53:43 2019\n",
      "Current rate is:  708\n",
      "Current NewsDesk Politics has  18 articles\n",
      "0.1 minutes until next newsDesk or max 20 mins Sun Mar 31 12:07:12 2019\n",
      "Current rate is:  828\n",
      "Current NewsDesk U.S. has  79 articles\n",
      "0.7 minutes until next newsDesk or max 20 mins Sun Mar 31 12:07:25 2019\n",
      "Current rate is:  830\n",
      "Current NewsDesk Washington has  776 articles\n",
      "7.7 minutes until next newsDesk or max 20 mins Sun Mar 31 12:08:19 2019\n",
      "Current rate is:  838\n",
      "After: Sun Mar 31 12:17:35 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Before: %s' % time.ctime())\n",
    "arts = []\n",
    "\n",
    "for i in newsDesk:\n",
    "    url = api_site + desk + i + '&' + dates + '&sort=oldest' + '&' + api_key\n",
    "    response = urllib.request.urlopen(url)\n",
    "    rateLimit += 1\n",
    "    articles = json.loads(response.read())\n",
    "    \n",
    "    print('Current NewsDesk',i,'has ',articles['response']['meta']['hits'],'articles')\n",
    "    print(int(articles['response']['meta']['hits']//10)*6/60,'minutes until next newsDesk or max 20 mins',time.ctime())\n",
    "    print('Current rate is: ',rateLimit)\n",
    "    # Sleep 6 second to avoid \"Exceeded Request Quota\" error\n",
    "    # 10 REQUESTS PER MINUTE\n",
    "    time.sleep(6)\n",
    "    \n",
    "    for j in range(0,min(int(articles['response']['meta']['hits']//10),200)):\n",
    "        # page limit of 200\n",
    "        response = urllib.request.urlopen(url+\"&page=\"+str(j))\n",
    "        rateLimit += 1\n",
    "        articles = json.loads(response.read())\n",
    "        arts.extend(articles['response']['docs'])\n",
    "                      \n",
    "        # Sleep 6 second to avoid \"Exceeded Request Quota\" error\n",
    "        # 10 REQUESTS PER MINUTE\n",
    "        time.sleep(6)\n",
    "        \n",
    "     \n",
    "        \n",
    "print('After: %s\\n' % time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Articles for NewsDesk: 2750'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Articles for NewsDesk: {}'.format(len(arts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.nytimes.com/svc/search/v2/articlesearch.json?fq=news_desk:Washington&begin_date=20180101&end_date=20180331&sort=oldest&api-key=zBxlhvG69zXIH0BooIEibFf56eJpv5Ny&page=76'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url+\"&page=\"+str(j) # last url requested. Good for checking errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Sun Mar 31 12:18:09 2019\n",
      "Current section Today%27s%20Headlines has  567 articles\n",
      "5.6 minutes until next section or max 20mins Sun Mar 31 12:18:18 2019\n",
      "Current rate is:  916\n",
      "Current section U.S. has  79 articles\n",
      "0.7 minutes until next section or max 20mins Sun Mar 31 12:26:15 2019\n",
      "Current rate is:  973\n",
      "Current section Washington has  776 articles\n",
      "7.7 minutes until next section or max 20mins Sun Mar 31 12:27:16 2019\n",
      "Current rate is:  981\n",
      "Current section Week in Review has  1650 articles\n",
      "16.5 minutes until next section or max 20mins Sun Mar 31 12:38:14 2019\n",
      "Current rate is:  1059\n",
      "After: Sun Mar 31 13:03:37 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Before: %s' % time.ctime())\n",
    "\n",
    "for i in sectionNV:\n",
    "    url = api_site + desk + i + '&' + dates + '&sort=oldest' + '&' + api_key\n",
    "    response = urllib.request.urlopen(url)\n",
    "    time.sleep(6)\n",
    "    rateLimit += 1\n",
    "    articles = json.loads(response.read())\n",
    "    \n",
    "    print('Current section',i,'has ',articles['response']['meta']['hits'],'articles')\n",
    "    print(int(articles['response']['meta']['hits']//10)*6/60,'minutes until next section or max 20mins',time.ctime())\n",
    "    print('Current rate is: ',rateLimit) \n",
    "    \n",
    "    for j in range(0,min(int(articles['response']['meta']['hits']//10),200)):\n",
    "        # page limit of 200\n",
    "        response = urllib.request.urlopen(url+\"&page=\"+str(j))\n",
    "        rateLimit += 1\n",
    "        articles = json.loads(response.read())\n",
    "        arts.extend(articles['response']['docs'])\n",
    "        \n",
    "        # Sleep 6 second to avoid \"Exceeded Request Quota\" error\n",
    "        # 10 REQUESTS PER MINUTE\n",
    "        time.sleep(6)\n",
    "        \n",
    "print('After: %s\\n' % time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Articles for NewsDesk and Section: 5800'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Articles for NewsDesk and Section: {}'.format(len(arts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "# all articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Sun Mar 31 14:25:33 2019\n",
      "After: Sun Mar 31 14:25:48 2019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Before: %s' % time.ctime())\n",
    "\n",
    "for i in range(0,len(arts)):\n",
    "    dic = {}\n",
    "    dic['id'] = arts[i]['_id']\n",
    "\n",
    "    dic['headline'] = arts[i]['headline']['main']\n",
    "    if ('news_desk' in arts[i]):\n",
    "        dic['news_desk'] = arts[i]['news_desk']\n",
    "    else:\n",
    "        dic['news_desk'] = 'NA'\n",
    "    dic['pub_date'] = arts[i]['pub_date'][0:10] # cutting time of day.\n",
    "    if ('section_name' in arts[i]):\n",
    "        dic['section'] = arts[i]['section_name']\n",
    "    else:\n",
    "        dic['section'] = 'NA'\n",
    "    if arts[i]['snippet'] is not None:\n",
    "        dic['snippet'] = arts[i]['snippet']\n",
    "    else:\n",
    "        dic['snippet'] = 'NA'\n",
    "    if ('source' in arts[i]):\n",
    "        dic['source'] = arts[i]['source']\n",
    "    else:\n",
    "        dic['source'] = 'NA'\n",
    "    if ('type_of_material' in arts[i]):\n",
    "        dic['type'] = arts[i]['type_of_material']\n",
    "    else:\n",
    "        dic['type'] = 'NA'\n",
    "    dic['url'] = arts[i]['web_url']\n",
    "    if ('word_count' in arts[i]):\n",
    "        dic['word_count'] = arts[i]['word_count']\n",
    "    # locations\n",
    "    locations = []\n",
    "    for x in range(0,len(arts[i]['keywords'])):\n",
    "        if 'glocations' in arts[i]['keywords'][x]['name']:\n",
    "            locations.append(arts[i]['keywords'][x]['value'])\n",
    "    dic['locations'] = locations\n",
    "    # subject\n",
    "    subjects = []\n",
    "    for x in range(0,len(arts[i]['keywords'])):\n",
    "        if 'subject' in arts[i]['keywords'][x]['name']:\n",
    "            subjects.append(arts[i]['keywords'][x]['value'])\n",
    "    dic['subjects'] = subjects   \n",
    "    news.append(dic)\n",
    "\n",
    "print('After: %s\\n' % time.ctime())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5800"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Capital Punishment Deserves a Quick Death',\n",
       " 'id': '5c8866d740d36ff070b63e64',\n",
       " 'locations': [],\n",
       " 'news_desk': 'Editorial',\n",
       " 'pub_date': '2018-01-01',\n",
       " 'section': 'Opinion',\n",
       " 'snippet': 'It’s time for the Supreme Court to end state-sanctioned killing for good.',\n",
       " 'source': 'The New York Times',\n",
       " 'subjects': ['Capital Punishment',\n",
       "  'Eighth Amendment (US Constitution)',\n",
       "  'Sentences (Criminal)'],\n",
       " 'type': 'Editorial',\n",
       " 'url': 'https://www.nytimes.com/2017/12/31/opinion/capital-punishment-death-penalty.html',\n",
       " 'word_count': 1062}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5800 articles for period begin_date=20180101&end_date=20180331'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} articles for period {}'.format(len(news),dates)\n",
    "# number of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'headline',\n",
       " 'news_desk',\n",
       " 'pub_date',\n",
       " 'section',\n",
       " 'snippet',\n",
       " 'source',\n",
       " 'type',\n",
       " 'url',\n",
       " 'word_count',\n",
       " 'locations',\n",
       " 'subjects']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['id','headline','news_desk','pub_date','section','snippet','source','type','url','word_count','locations','subjects']\n",
    "# column headers\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will replace existing file. If you only want to add to the file, \n",
    "# skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('articles.txt','w')\n",
    "\n",
    "for i in headers:\n",
    "    file.write(i)\n",
    "    file.write('\\t')\n",
    "file.close()\n",
    "\n",
    "#only do the first time to add headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('articles.txt','a')\n",
    "\n",
    "for i in range(0,len(news)):\n",
    "    file.write('\\n')\n",
    "    for j in headers:        \n",
    "        file.write(re.sub(r'[^\\x00-\\x7F]','',str(news[i][j]))) # remove unicode chars\n",
    "        file.write('\\t')\n",
    "file.close()\n",
    "\n",
    "# add articles to existing text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5800"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
